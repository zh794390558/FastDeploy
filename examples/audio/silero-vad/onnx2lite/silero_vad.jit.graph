graph(%self.1 : __torch__.vad.model.vad_annotator.VADRNNJITMerge,
      %x.1 : Tensor,
      %sr.1 : int):
  %3 : str = prim::Constant[value="builtins.ValueError"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:381:18
  %4 : str = prim::Constant[value=""]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:381:18
  %5 : bool = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:371:12
  %6 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:73
  %7 : int = prim::Constant[value=16000]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:376:17
  %8 : int = prim::Constant[value=8000]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:378:19
  %9 : int = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:384:46
  %10 : Tensor = prim::Uninitialized() # :0:0
  %49 : float = prim::Constant[value=31.25]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:29
  %50 : int = prim::Constant[value=16000]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:17
  %51 : int = prim::Constant[value=2]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:352:21
  %52 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:351:28
  %53 : int = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:350:22
  %54 : str = prim::Constant[value="Too many dimensions for input audio chunk {}"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:353:29
  %55 : str = prim::Constant[value="Supported sampling rates: {} (or multiply of 16000)"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:361:29
  %56 : str = prim::Constant[value="builtins.ValueError"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:353:18
  %57 : bool = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:11
  %58 : NoneType = prim::Constant() # :0:0
  %59 : str = prim::Constant[value="Input audio chunk is too short"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:364:29
  %60 : int = aten::dim(%x.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:350:11
  %61 : bool = aten::eq(%60, %53) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:350:11
  %x1 : Tensor = prim::If(%61) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:350:8
    block0():
      %x1.3 : Tensor = aten::unsqueeze(%x.1, %52) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:351:16
      -> (%x1.3)
    block1():
      -> (%x.1)
  %64 : int = aten::dim(%x1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:352:11
  %65 : bool = aten::gt(%64, %51) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:352:11
   = prim::If(%65) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:352:8
    block0():
      %66 : int = aten::dim(%x1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:353:74
      %67 : str = aten::format(%54, %66) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:353:29
       = prim::RaiseException(%67, %56) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:353:12
      -> ()
    block1():
      -> ()
  %68 : bool = aten::ne(%sr.1, %50) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:11
  %69 : bool = prim::If(%68) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:11
    block0():
      %70 : int = aten::remainder(%sr.1, %50) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:28
      %71 : bool = aten::eq(%70, %52) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:28
      -> (%71)
    block1():
      -> (%57)
  %sr1 : int, %x2 : Tensor = prim::If(%69) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:355:8
    block0():
      %step.1 : int = aten::floordiv(%sr.1, %50) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:356:19
      %x3.2 : Tensor = aten::slice(%x1, %52, %58, %58, %step.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:357:16
      -> (%50, %x3.2)
    block1():
      -> (%sr.1, %x1)
  %sample_rates.1 : int[] = prim::GetAttr[name="sample_rates"](%self.1)
  %77 : bool = aten::__contains__(%sample_rates.1, %sr1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:360:11
  %78 : bool = aten::__not__(%77) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:360:11
   = prim::If(%78) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:360:8
    block0():
      %sample_rates : int[] = prim::GetAttr[name="sample_rates"](%self.1)
      %80 : str = aten::format(%55, %sample_rates) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:361:29
       = prim::RaiseException(%80, %56) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:361:12
      -> ()
    block1():
      -> ()
  %81 : int[] = aten::size(%x2) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:16
  %82 : int = aten::__getitem__(%81, %53) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:16
  %83 : float = aten::div(%sr1, %82) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:11
  %84 : bool = aten::gt(%83, %49) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:11
   = prim::If(%84) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:363:8
    block0():
       = prim::RaiseException(%59, %56) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:364:12
      -> ()
    block1():
      -> ()
  %85 : (Tensor, int) = prim::TupleConstruct(%x2, %sr1)
  %x0.3 : Tensor, %sr0.1 : int = prim::TupleUnpack(%85)
  %_last_sr.1 : int = prim::GetAttr[name="_last_sr"](%self.1)
  %15 : bool = aten::Bool(%_last_sr.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:371:12
  %16 : bool = prim::If(%15) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:371:12
    block0():
      %_last_sr : int = prim::GetAttr[name="_last_sr"](%self.1)
      %18 : bool = aten::ne(%_last_sr, %sr0.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:371:32
      -> (%18)
    block1():
      -> (%5)
   = prim::If(%16) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:371:8
    block0():
      %86 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:343:30
      %87 : NoneType = prim::Constant()
      %88 : int[] = prim::ListConstruct(%86)
      %89 : Tensor = aten::zeros(%88, %87, %87, %87, %87) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:343:18
       = prim::SetAttr[name="_h"](%self.1, %89)
      %90 : int[] = prim::ListConstruct(%86)
      %91 : Tensor = aten::zeros(%90, %87, %87, %87, %87) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:344:18
       = prim::SetAttr[name="_c"](%self.1, %91)
       = prim::SetAttr[name="_last_sr"](%self.1, %86)
       = prim::SetAttr[name="_last_batch_size"](%self.1, %86)
      -> ()
    block1():
      -> ()
  %_last_batch_size.1 : int = prim::GetAttr[name="_last_batch_size"](%self.1)
  %21 : bool = aten::Bool(%_last_batch_size.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:12
  %22 : bool = prim::If(%21) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:12
    block0():
      %_last_batch_size : int = prim::GetAttr[name="_last_batch_size"](%self.1)
      %24 : int[] = aten::size(%x0.3) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:65
      %25 : int = aten::__getitem__(%24, %6) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:65
      %26 : bool = aten::ne(%_last_batch_size, %25) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:40
      -> (%26)
    block1():
      -> (%5)
   = prim::If(%22) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:373:8
    block0():
      %92 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:343:30
      %93 : NoneType = prim::Constant()
      %94 : int[] = prim::ListConstruct(%92)
      %95 : Tensor = aten::zeros(%94, %93, %93, %93, %93) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:343:18
       = prim::SetAttr[name="_h"](%self.1, %95)
      %96 : int[] = prim::ListConstruct(%92)
      %97 : Tensor = aten::zeros(%96, %93, %93, %93, %93) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:344:18
       = prim::SetAttr[name="_c"](%self.1, %97)
       = prim::SetAttr[name="_last_sr"](%self.1, %92)
       = prim::SetAttr[name="_last_batch_size"](%self.1, %92)
      -> ()
    block1():
      -> ()
  %28 : bool = aten::eq(%sr0.1, %7) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:376:11
  %out : Tensor = prim::If(%28) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:376:8
    block0():
      %_model.1 : __torch__.vad.model.vad_annotator.___torch_mangle_28.VADRNNJIT = prim::GetAttr[name="_model"](%self.1)
      %_h.1 : Tensor = prim::GetAttr[name="_h"](%self.1)
      %_c.1 : Tensor = prim::GetAttr[name="_c"](%self.1)
      %98 : str = prim::Constant[value="Expected hidden[1] size {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:696:31
      %99 : str = prim::Constant[value="Expected hidden[0] size {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:694:31
      %100 : str = prim::Constant[value="input must have {} dimensions, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
      %101 : str = prim::Constant[value="input.size(-1) must be equal to input_size. Expected {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
      %102 : int = prim::Constant[value=64]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:741:73
      %103 : int = prim::Constant[value=3]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:40
      %104 : str = prim::Constant[value="For batched 3-D input, hx and cx should also be 3-D but got ({}-D, {}-D) tensors"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:31
      %105 : str = prim::Constant[value="For unbatched 2-D input, hx and cx should also be 2-D but got ({}-D, {}-D) tensors"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:31
      %106 : str = prim::Constant[value="builtins.RuntimeError"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:755:30
      %107 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
      %108 : str = prim::Constant[value="builtins.ValueError"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:298:18
      %109 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:179:12
      %110 : float = prim::Constant[value=0.10000000000000001]() # :0:0
      %111 : int = prim::Constant[value=16]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
      %112 : int = prim::Constant[value=32]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
      %113 : int = prim::Constant[value=258]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
      %114 : float = prim::Constant[value=0.14999999999999999]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/dropout.py:58:32
      %115 : int[] = prim::Constant[value=[0]]()
      %116 : Function = prim::Constant[name="simple_pad"]()
      %117 : bool = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:409:41
      %118 : int = prim::Constant[value=1048576]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:36
      %119 : int = prim::Constant[value=-1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:412:34
      %120 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:38:43
      %121 : int = prim::Constant[value=6]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
      %122 : int = prim::Constant[value=2]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:62
      %123 : str = prim::Constant[value="reflect"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:81
      %124 : int[] = prim::Constant[value=[1]]()
      %125 : int = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:294:40
      %126 : bool = prim::Constant[value=0]()
      %127 : NoneType = prim::Constant()
      %feature_extractor.2 : __torch__.vad.utils.pytorch_stft.STFT = prim::GetAttr[name="feature_extractor"](%_model.1)
      %num_batches.2 : int = aten::size(%x0.3, %120) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:41:22
      %num_samples.2 : int = aten::size(%x0.3, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:42:22
      %131 : int[] = prim::ListConstruct(%num_batches.2, %125, %num_samples.2)
      %input_data0.2 : Tensor = aten::view(%x0.3, %131) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:44:21
      %filter_length.2 : int = prim::GetAttr[name="filter_length"](%feature_extractor.2)
      %hop_length.2 : int = prim::GetAttr[name="hop_length"](%feature_extractor.2)
      %135 : int = aten::sub(%filter_length.2, %hop_length.2) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:22
      %136 : float = aten::div(%135, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:22
      %to_pad.3 : int = aten::Int(%136) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:17
      %138 : Tensor = aten::unsqueeze(%input_data0.2, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:27
      %139 : int[] = prim::ListConstruct(%to_pad.3, %to_pad.3, %120, %120)
      %input_data1.2 : Tensor = aten::pad(%138, %139, %123, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:21
      %input_data2.2 : Tensor = aten::squeeze(%input_data1.2, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:48:21
      %forward_basis_buffer.2 : Tensor = prim::GetAttr[name="forward_basis_buffer"](%feature_extractor.2)
      %hop_length.4 : int = prim::GetAttr[name="hop_length"](%feature_extractor.2)
      %144 : int[] = prim::ListConstruct(%hop_length.4)
      %145 : int[] = prim::ListConstruct(%120)
      %forward_transform.2 : Tensor = aten::conv1d(%input_data2.2, %forward_basis_buffer.2, %127, %144, %145, %124, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:50:28
      %filter_length.4 : int = prim::GetAttr[name="filter_length"](%feature_extractor.2)
      %148 : float = aten::div(%filter_length.4, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:22
      %149 : float = aten::add(%148, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:22
      %cutoff.2 : int = aten::Int(%149) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:17
      %151 : Tensor = aten::slice(%forward_transform.2, %120, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
      %152 : Tensor = aten::slice(%151, %125, %127, %cutoff.2, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
      %153 : Tensor = aten::slice(%152, %122, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
      %real_part.2 : Tensor = aten::to(%153, %121, %126, %126, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
      %155 : Tensor = aten::slice(%forward_transform.2, %120, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
      %156 : Tensor = aten::slice(%155, %125, %cutoff.2, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
      %157 : Tensor = aten::slice(%156, %122, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
      %imag_part.2 : Tensor = aten::to(%157, %121, %126, %126, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
      %159 : Tensor = aten::pow(%real_part.2, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:31
      %160 : Tensor = aten::pow(%imag_part.2, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:46
      %161 : Tensor = aten::add(%159, %160, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:31
      %magnitude.2 : Tensor = aten::sqrt(%161) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:20
      %163 : Tensor = prim::data(%imag_part.2) # :0:0
      %164 : Tensor = prim::data(%real_part.2) # :0:0
      %phase.2 : Tensor = aten::atan2(%163, %164) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:61:16
      %166 : (Tensor, Tensor) = prim::TupleConstruct(%magnitude.2, %phase.2)
      %x0.7 : Tensor = prim::TupleIndex(%166, %120)
      %adaptive_normalization.2 : __torch__.models.stt_model_blocks.AdaptiveAudioNormalizationNew = prim::GetAttr[name="adaptive_normalization"](%_model.1)
      %169 : Tensor = aten::mul(%x0.7, %118) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:28
      %spect0.2 : Tensor = aten::log1p(%169) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:16
      %171 : int[] = aten::size(%spect0.2) # <string>:13:9
      %172 : int = aten::len(%171) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:11
      %173 : bool = aten::eq(%172, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:11
      %spect1.2 : Tensor = prim::If(%173) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:8
        block0():
          %175 : Tensor = aten::unsqueeze(%spect0.2, %120) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
          %176 : Tensor = aten::slice(%175, %125, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
          %spect1.4 : Tensor = aten::slice(%176, %122, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
          -> (%spect1.4)
        block1():
          -> (%spect0.2)
      %178 : int[] = prim::ListConstruct(%125)
      %mean.2 : Tensor = aten::mean(%spect1.2, %178, %117, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:409:15
      %to_pad.5 : int = prim::GetAttr[name="to_pad"](%adaptive_normalization.2)
      %181 : Tensor = aten::slice(%mean.2, %120, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
      %182 : Tensor = aten::slice(%181, %125, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
      %183 : int = aten::add(%to_pad.5, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:37
      %184 : Tensor = aten::slice(%182, %122, %125, %183, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
      %185 : int[] = prim::ListConstruct(%119)
      %left_pad.2 : Tensor = aten::flip(%184, %185) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:15
      %187 : Tensor = aten::slice(%mean.2, %120, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
      %188 : Tensor = aten::slice(%187, %125, %127, %127, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
      %189 : int = aten::sub(%119, %to_pad.5) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:35
      %190 : Tensor = aten::slice(%188, %122, %189, %119, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
      %191 : int[] = prim::ListConstruct(%119)
      %right_pad.2 : Tensor = aten::flip(%190, %191) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:16
      %193 : Tensor[] = prim::ListConstruct(%left_pad.2, %mean.2, %right_pad.2)
      %mean0.2 : Tensor = aten::cat(%193, %122) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:394:11
      %filter_.2 : Tensor = prim::GetAttr[name="filter_"](%adaptive_normalization.2)
      %mean1.2 : Tensor = aten::conv1d(%mean0.2, %filter_.2, %127, %124, %115, %124, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:411:15
      %197 : int[] = prim::ListConstruct(%119)
      %mean_mean.2 : Tensor = aten::mean(%mean1.2, %197, %117, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:412:20
      %199 : Tensor = aten::neg(%mean_mean.2) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:413:26
      %norm.2 : Tensor = aten::add(%spect1.2, %199, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:413:16
      %201 : Tensor[] = prim::ListConstruct(%x0.7, %norm.2)
      %x1.7 : Tensor = aten::cat(%201, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:294:12
      %first_layer.2 : __torch__.torch.nn.modules.container.___torch_mangle_2.Sequential = prim::GetAttr[name="first_layer"](%_model.1)
      %_0.10 : __torch__.models.number_vad_model.ConvBlock = prim::GetAttr[name="0"](%first_layer.2)
      %_1.7 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="1"](%first_layer.2)
      %pw_conv.5 : __torch__.torch.nn.modules.container.___torch_mangle_1.Sequential = prim::GetAttr[name="pw_conv"](%_0.10)
      %dw_conv.5 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="dw_conv"](%_0.10)
      %_0.12 : __torch__.torch.nn.modules.conv.Conv1d = prim::GetAttr[name="0"](%dw_conv.5)
      %_1.9 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name="1"](%dw_conv.5)
      %_2.1 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="2"](%dw_conv.5)
      %weight.11 : Tensor = prim::GetAttr[name="weight"](%_0.12)
      %bias.11 : Tensor? = prim::GetAttr[name="bias"](%_0.12)
      %213 : int[] = prim::ListConstruct(%125)
      %214 : int[] = prim::ListConstruct(%122)
      %215 : int[] = prim::ListConstruct(%125)
      %input1.3 : Tensor = aten::conv1d(%x1.7, %weight.11, %bias.11, %213, %214, %215, %113) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %result.8 : Tensor = aten::relu(%input1.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.14 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv1d = prim::GetAttr[name="0"](%pw_conv.5)
      %_1.12 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name="1"](%pw_conv.5)
      %weight.13 : Tensor = prim::GetAttr[name="weight"](%_0.14)
      %bias.13 : Tensor? = prim::GetAttr[name="bias"](%_0.14)
      %222 : int[] = prim::ListConstruct(%125)
      %223 : int[] = prim::ListConstruct(%120)
      %224 : int[] = prim::ListConstruct(%125)
      %x0.9 : Tensor = aten::conv1d(%result.8, %weight.13, %bias.13, %222, %223, %224, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %proj.4 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv1d = prim::GetAttr[name="proj"](%_0.10)
      %weight.15 : Tensor = prim::GetAttr[name="weight"](%proj.4)
      %bias.15 : Tensor? = prim::GetAttr[name="bias"](%proj.4)
      %229 : int[] = prim::ListConstruct(%125)
      %230 : int[] = prim::ListConstruct(%120)
      %231 : int[] = prim::ListConstruct(%125)
      %residual.4 : Tensor = aten::conv1d(%x1.7, %weight.15, %bias.15, %229, %230, %231, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %x1.9 : Tensor = aten::add_(%x0.9, %residual.4, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
      %activation.2 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name="activation"](%_0.10)
      %input0.10 : Tensor = aten::relu(%x1.9) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %training.9 : bool = prim::GetAttr[name="training"](%_1.7)
      %x2.4 : Tensor = aten::dropout(%input0.10, %114, %training.9) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
      %encoder.2 : __torch__.torch.nn.modules.container.___torch_mangle_27.Sequential = prim::GetAttr[name="encoder"](%_model.1)
      %_0.16 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv1d = prim::GetAttr[name="0"](%encoder.2)
      %_1.14 : __torch__.torch.nn.modules.batchnorm.BatchNorm1d = prim::GetAttr[name="1"](%encoder.2)
      %_3.1 : __torch__.torch.nn.modules.container.___torch_mangle_9.Sequential = prim::GetAttr[name="3"](%encoder.2)
      %_4.1 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv1d = prim::GetAttr[name="4"](%encoder.2)
      %_5.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm1d = prim::GetAttr[name="5"](%encoder.2)
      %_7.1 : __torch__.torch.nn.modules.container.___torch_mangle_17.Sequential = prim::GetAttr[name="7"](%encoder.2)
      %_8.1 : __torch__.torch.nn.modules.conv.___torch_mangle_10.Conv1d = prim::GetAttr[name="8"](%encoder.2)
      %_9.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_11.BatchNorm1d = prim::GetAttr[name="9"](%encoder.2)
      %_11.1 : __torch__.torch.nn.modules.container.___torch_mangle_21.Sequential = prim::GetAttr[name="11"](%encoder.2)
      %_12.1 : __torch__.torch.nn.modules.conv.___torch_mangle_22.Conv1d = prim::GetAttr[name="12"](%encoder.2)
      %_13.1 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_23.BatchNorm1d = prim::GetAttr[name="13"](%encoder.2)
      %weight.17 : Tensor = prim::GetAttr[name="weight"](%_0.16)
      %bias.17 : Tensor? = prim::GetAttr[name="bias"](%_0.16)
      %252 : int[] = prim::ListConstruct(%122)
      %253 : int[] = prim::ListConstruct(%120)
      %254 : int[] = prim::ListConstruct(%125)
      %input0.12 : Tensor = aten::conv1d(%x2.4, %weight.17, %bias.17, %252, %253, %254, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %training.11 : bool = prim::GetAttr[name="training"](%_1.14)
       = prim::If(%training.11) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
        block0():
          %num_batches_tracked.3 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.14)
          %258 : Tensor = aten::add_(%num_batches_tracked.3, %125, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
          -> ()
        block1():
          -> ()
      %training.13 : bool = prim::GetAttr[name="training"](%_1.14)
      %running_mean.3 : Tensor = prim::GetAttr[name="running_mean"](%_1.14)
      %running_var.3 : Tensor = prim::GetAttr[name="running_var"](%_1.14)
      %weight.19 : Tensor = prim::GetAttr[name="weight"](%_1.14)
      %bias.19 : Tensor = prim::GetAttr[name="bias"](%_1.14)
       = prim::If(%training.13) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
        block0():
          %264 : int[] = aten::size(%input0.12) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
          %size_prods.3 : int = aten::__getitem__(%264, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
          %266 : int = aten::len(%264) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %267 : int = aten::sub(%266, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %size_prods0.2 : int = prim::Loop(%267, %117, %size_prods.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
            block0(%i.3 : int, %size_prods0.9 : int):
              %271 : int = aten::add(%i.3, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
              %272 : int = aten::__getitem__(%264, %271) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
              %size_prods1.3 : int = aten::mul(%size_prods0.9, %272) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
              -> (%117, %size_prods1.3)
          %274 : bool = aten::eq(%size_prods0.2, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
           = prim::If(%274) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
            block0():
              %275 : str = aten::format(%107, %264) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
               = prim::RaiseException(%275, %108) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input1.7 : Tensor = aten::batch_norm(%input0.12, %weight.19, %bias.19, %running_mean.3, %running_var.3, %training.13, %110, %109, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
      %input2.2 : Tensor = aten::relu(%input1.7) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.18 : __torch__.models.number_vad_model.___torch_mangle_8.ConvBlock = prim::GetAttr[name="0"](%_3.1)
      %_1.16 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="1"](%_3.1)
      %pw_conv.7 : __torch__.torch.nn.modules.container.___torch_mangle_7.Sequential = prim::GetAttr[name="pw_conv"](%_0.18)
      %dw_conv.7 : __torch__.torch.nn.modules.container.___torch_mangle_5.Sequential = prim::GetAttr[name="dw_conv"](%_0.18)
      %_0.20 : __torch__.torch.nn.modules.conv.___torch_mangle_4.Conv1d = prim::GetAttr[name="0"](%dw_conv.7)
      %weight.21 : Tensor = prim::GetAttr[name="weight"](%_0.20)
      %bias.21 : Tensor? = prim::GetAttr[name="bias"](%_0.20)
      %285 : int[] = prim::ListConstruct(%125)
      %286 : int[] = prim::ListConstruct(%122)
      %287 : int[] = prim::ListConstruct(%125)
      %input1.9 : Tensor = aten::conv1d(%input2.2, %weight.21, %bias.21, %285, %286, %287, %111) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %result.10 : Tensor = aten::relu(%input1.9) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.22 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv1d = prim::GetAttr[name="0"](%pw_conv.7)
      %weight.25 : Tensor = prim::GetAttr[name="weight"](%_0.22)
      %bias.25 : Tensor? = prim::GetAttr[name="bias"](%_0.22)
      %293 : int[] = prim::ListConstruct(%125)
      %294 : int[] = prim::ListConstruct(%120)
      %295 : int[] = prim::ListConstruct(%125)
      %x0.11 : Tensor = aten::conv1d(%result.10, %weight.25, %bias.25, %293, %294, %295, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %proj.6 : __torch__.torch.nn.modules.conv.___torch_mangle_6.Conv1d = prim::GetAttr[name="proj"](%_0.18)
      %weight.27 : Tensor = prim::GetAttr[name="weight"](%proj.6)
      %bias.27 : Tensor? = prim::GetAttr[name="bias"](%proj.6)
      %300 : int[] = prim::ListConstruct(%125)
      %301 : int[] = prim::ListConstruct(%120)
      %302 : int[] = prim::ListConstruct(%125)
      %residual.6 : Tensor = aten::conv1d(%input2.2, %weight.27, %bias.27, %300, %301, %302, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %x1.11 : Tensor = aten::add_(%x0.11, %residual.6, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
      %input0.14 : Tensor = aten::relu(%x1.11) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %training.15 : bool = prim::GetAttr[name="training"](%_1.16)
      %input3.2 : Tensor = aten::dropout(%input0.14, %114, %training.15) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
      %weight.29 : Tensor = prim::GetAttr[name="weight"](%_4.1)
      %bias.29 : Tensor? = prim::GetAttr[name="bias"](%_4.1)
      %310 : int[] = prim::ListConstruct(%122)
      %311 : int[] = prim::ListConstruct(%120)
      %312 : int[] = prim::ListConstruct(%125)
      %input4.2 : Tensor = aten::conv1d(%input3.2, %weight.29, %bias.29, %310, %311, %312, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %training.17 : bool = prim::GetAttr[name="training"](%_5.1)
       = prim::If(%training.17) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
        block0():
          %num_batches_tracked.5 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_5.1)
          %316 : Tensor = aten::add_(%num_batches_tracked.5, %125, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
          -> ()
        block1():
          -> ()
      %training.19 : bool = prim::GetAttr[name="training"](%_5.1)
      %running_mean.5 : Tensor = prim::GetAttr[name="running_mean"](%_5.1)
      %running_var.5 : Tensor = prim::GetAttr[name="running_var"](%_5.1)
      %weight.31 : Tensor = prim::GetAttr[name="weight"](%_5.1)
      %bias.31 : Tensor = prim::GetAttr[name="bias"](%_5.1)
       = prim::If(%training.19) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
        block0():
          %322 : int[] = aten::size(%input4.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
          %size_prods.5 : int = aten::__getitem__(%322, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
          %324 : int = aten::len(%322) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %325 : int = aten::sub(%324, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %size_prods0.11 : int = prim::Loop(%325, %117, %size_prods.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
            block0(%i.5 : int, %size_prods0.13 : int):
              %329 : int = aten::add(%i.5, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
              %330 : int = aten::__getitem__(%322, %329) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
              %size_prods1.5 : int = aten::mul(%size_prods0.13, %330) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
              -> (%117, %size_prods1.5)
          %332 : bool = aten::eq(%size_prods0.11, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
           = prim::If(%332) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
            block0():
              %333 : str = aten::format(%107, %322) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
               = prim::RaiseException(%333, %108) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input5.2 : Tensor = aten::batch_norm(%input4.2, %weight.31, %bias.31, %running_mean.5, %running_var.5, %training.19, %110, %109, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
      %input6.2 : Tensor = aten::relu(%input5.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.24 : __torch__.models.number_vad_model.___torch_mangle_16.ConvBlock = prim::GetAttr[name="0"](%_7.1)
      %_1.18 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="1"](%_7.1)
      %pw_conv.9 : __torch__.torch.nn.modules.container.___torch_mangle_15.Sequential = prim::GetAttr[name="pw_conv"](%_0.24)
      %dw_conv.9 : __torch__.torch.nn.modules.container.___torch_mangle_13.Sequential = prim::GetAttr[name="dw_conv"](%_0.24)
      %_0.26 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv1d = prim::GetAttr[name="0"](%dw_conv.9)
      %weight.33 : Tensor = prim::GetAttr[name="weight"](%_0.26)
      %bias.33 : Tensor? = prim::GetAttr[name="bias"](%_0.26)
      %343 : int[] = prim::ListConstruct(%125)
      %344 : int[] = prim::ListConstruct(%122)
      %345 : int[] = prim::ListConstruct(%125)
      %input1.11 : Tensor = aten::conv1d(%input6.2, %weight.33, %bias.33, %343, %344, %345, %112) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %result.12 : Tensor = aten::relu(%input1.11) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.28 : __torch__.torch.nn.modules.conv.___torch_mangle_14.Conv1d = prim::GetAttr[name="0"](%pw_conv.9)
      %weight.35 : Tensor = prim::GetAttr[name="weight"](%_0.28)
      %bias.35 : Tensor? = prim::GetAttr[name="bias"](%_0.28)
      %351 : int[] = prim::ListConstruct(%125)
      %352 : int[] = prim::ListConstruct(%120)
      %353 : int[] = prim::ListConstruct(%125)
      %x0.13 : Tensor = aten::conv1d(%result.12, %weight.35, %bias.35, %351, %352, %353, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %x1.13 : Tensor = aten::add_(%x0.13, %input6.2, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
      %input0.16 : Tensor = aten::relu(%x1.13) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %training.21 : bool = prim::GetAttr[name="training"](%_1.18)
      %input7.2 : Tensor = aten::dropout(%input0.16, %114, %training.21) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
      %weight.37 : Tensor = prim::GetAttr[name="weight"](%_8.1)
      %bias.37 : Tensor? = prim::GetAttr[name="bias"](%_8.1)
      %361 : int[] = prim::ListConstruct(%122)
      %362 : int[] = prim::ListConstruct(%120)
      %363 : int[] = prim::ListConstruct(%125)
      %input8.2 : Tensor = aten::conv1d(%input7.2, %weight.37, %bias.37, %361, %362, %363, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %training.23 : bool = prim::GetAttr[name="training"](%_9.1)
       = prim::If(%training.23) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
        block0():
          %num_batches_tracked.7 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_9.1)
          %367 : Tensor = aten::add_(%num_batches_tracked.7, %125, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
          -> ()
        block1():
          -> ()
      %training.25 : bool = prim::GetAttr[name="training"](%_9.1)
      %running_mean.7 : Tensor = prim::GetAttr[name="running_mean"](%_9.1)
      %running_var.7 : Tensor = prim::GetAttr[name="running_var"](%_9.1)
      %weight.39 : Tensor = prim::GetAttr[name="weight"](%_9.1)
      %bias.39 : Tensor = prim::GetAttr[name="bias"](%_9.1)
       = prim::If(%training.25) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
        block0():
          %373 : int[] = aten::size(%input8.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
          %size_prods.7 : int = aten::__getitem__(%373, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
          %375 : int = aten::len(%373) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %376 : int = aten::sub(%375, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %size_prods0.15 : int = prim::Loop(%376, %117, %size_prods.7) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
            block0(%i.7 : int, %size_prods0.17 : int):
              %380 : int = aten::add(%i.7, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
              %381 : int = aten::__getitem__(%373, %380) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
              %size_prods1.7 : int = aten::mul(%size_prods0.17, %381) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
              -> (%117, %size_prods1.7)
          %383 : bool = aten::eq(%size_prods0.15, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
           = prim::If(%383) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
            block0():
              %384 : str = aten::format(%107, %373) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
               = prim::RaiseException(%384, %108) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input9.2 : Tensor = aten::batch_norm(%input8.2, %weight.39, %bias.39, %running_mean.7, %running_var.7, %training.25, %110, %109, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
      %input10.2 : Tensor = aten::relu(%input9.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.30 : __torch__.models.number_vad_model.___torch_mangle_20.ConvBlock = prim::GetAttr[name="0"](%_11.1)
      %_1.20 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="1"](%_11.1)
      %pw_conv.11 : __torch__.torch.nn.modules.container.___torch_mangle_19.Sequential = prim::GetAttr[name="pw_conv"](%_0.30)
      %dw_conv.11 : __torch__.torch.nn.modules.container.___torch_mangle_13.Sequential = prim::GetAttr[name="dw_conv"](%_0.30)
      %_0.32 : __torch__.torch.nn.modules.conv.___torch_mangle_12.Conv1d = prim::GetAttr[name="0"](%dw_conv.11)
      %weight.41 : Tensor = prim::GetAttr[name="weight"](%_0.32)
      %bias.41 : Tensor? = prim::GetAttr[name="bias"](%_0.32)
      %394 : int[] = prim::ListConstruct(%125)
      %395 : int[] = prim::ListConstruct(%122)
      %396 : int[] = prim::ListConstruct(%125)
      %input1.13 : Tensor = aten::conv1d(%input10.2, %weight.41, %bias.41, %394, %395, %396, %112) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %result.14 : Tensor = aten::relu(%input1.13) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %_0.34 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv1d = prim::GetAttr[name="0"](%pw_conv.11)
      %weight.43 : Tensor = prim::GetAttr[name="weight"](%_0.34)
      %bias.43 : Tensor? = prim::GetAttr[name="bias"](%_0.34)
      %402 : int[] = prim::ListConstruct(%125)
      %403 : int[] = prim::ListConstruct(%120)
      %404 : int[] = prim::ListConstruct(%125)
      %x0.15 : Tensor = aten::conv1d(%result.14, %weight.43, %bias.43, %402, %403, %404, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %proj.8 : __torch__.torch.nn.modules.conv.___torch_mangle_18.Conv1d = prim::GetAttr[name="proj"](%_0.30)
      %weight.45 : Tensor = prim::GetAttr[name="weight"](%proj.8)
      %bias.45 : Tensor? = prim::GetAttr[name="bias"](%proj.8)
      %409 : int[] = prim::ListConstruct(%125)
      %410 : int[] = prim::ListConstruct(%120)
      %411 : int[] = prim::ListConstruct(%125)
      %residual.8 : Tensor = aten::conv1d(%input10.2, %weight.45, %bias.45, %409, %410, %411, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %x1.10 : Tensor = aten::add_(%x0.15, %residual.8, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
      %input0.18 : Tensor = aten::relu(%x1.10) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %training.27 : bool = prim::GetAttr[name="training"](%_1.20)
      %input11.2 : Tensor = aten::dropout(%input0.18, %114, %training.27) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
      %weight.47 : Tensor = prim::GetAttr[name="weight"](%_12.1)
      %bias.47 : Tensor? = prim::GetAttr[name="bias"](%_12.1)
      %419 : int[] = prim::ListConstruct(%125)
      %420 : int[] = prim::ListConstruct(%120)
      %421 : int[] = prim::ListConstruct(%125)
      %input12.2 : Tensor = aten::conv1d(%input11.2, %weight.47, %bias.47, %419, %420, %421, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %training.29 : bool = prim::GetAttr[name="training"](%_13.1)
       = prim::If(%training.29) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
        block0():
          %num_batches_tracked.9 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_13.1)
          %425 : Tensor = aten::add_(%num_batches_tracked.9, %125, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
          -> ()
        block1():
          -> ()
      %training.31 : bool = prim::GetAttr[name="training"](%_13.1)
      %running_mean.9 : Tensor = prim::GetAttr[name="running_mean"](%_13.1)
      %running_var.9 : Tensor = prim::GetAttr[name="running_var"](%_13.1)
      %weight.49 : Tensor = prim::GetAttr[name="weight"](%_13.1)
      %bias.49 : Tensor = prim::GetAttr[name="bias"](%_13.1)
       = prim::If(%training.31) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
        block0():
          %431 : int[] = aten::size(%input12.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
          %size_prods.9 : int = aten::__getitem__(%431, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
          %433 : int = aten::len(%431) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %434 : int = aten::sub(%433, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
          %size_prods0.19 : int = prim::Loop(%434, %117, %size_prods.9) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
            block0(%i.9 : int, %size_prods0.21 : int):
              %438 : int = aten::add(%i.9, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
              %439 : int = aten::__getitem__(%431, %438) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
              %size_prods1.9 : int = aten::mul(%size_prods0.21, %439) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
              -> (%117, %size_prods1.9)
          %441 : bool = aten::eq(%size_prods0.19, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
           = prim::If(%441) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
            block0():
              %442 : str = aten::format(%107, %431) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
               = prim::RaiseException(%442, %108) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input13.2 : Tensor = aten::batch_norm(%input12.2, %weight.49, %bias.49, %running_mean.9, %running_var.9, %training.31, %110, %109, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
      %x3.4 : Tensor = aten::relu(%input13.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %decoder.3 : __torch__.vad.model.vad_annotator.VADDecoderRNNJIT = prim::GetAttr[name="decoder"](%_model.1)
      %446 : int = aten::len(%_h.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:11
      %447 : bool = aten::Bool(%446) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:11
      %x0 : Tensor, %h0 : Tensor, %c0 : Tensor = prim::If(%447) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:8
        block0():
          %rnn.2 : __torch__.torch.nn.modules.rnn.LSTM = prim::GetAttr[name="rnn"](%decoder.3)
          %452 : int[] = prim::ListConstruct(%120, %122, %125)
          %453 : Tensor = aten::permute(%x3.4, %452) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:235:33
          %454 : (Tensor, Tensor) = prim::TupleConstruct(%_h.1, %_c.1)
          %455 : int = aten::dim(%453) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
          %is_batched.3 : bool = aten::eq(%455, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
          %457 : bool = aten::__not__(%is_batched.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:15
          %input0.20 : Tensor = prim::If(%457) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:12
            block0():
              %input0.22 : Tensor = aten::unsqueeze(%453, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:734:24
              -> (%input0.22)
            block1():
              -> (%453)
          %hx2.2 : (Tensor, Tensor) = prim::If(%is_batched.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:751:16
            block0():
              %461 : Tensor = prim::TupleIndex(%454, %120)
              %462 : int = aten::dim(%461) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
              %463 : bool = aten::ne(%462, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
              %464 : bool = prim::If(%463) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
                block0():
                  -> (%117)
                block1():
                  %465 : Tensor = prim::TupleIndex(%454, %125)
                  %466 : int = aten::dim(%465) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:44
                  %467 : bool = aten::ne(%466, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:44
                  -> (%467)
               = prim::If(%464) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:20
                block0():
                  %468 : Tensor = prim::TupleIndex(%454, %120)
                  %469 : int = aten::dim(%468) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:32
                  %470 : Tensor = prim::TupleIndex(%454, %125)
                  %471 : int = aten::dim(%470) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:32
                  %msg.3 : str = aten::format(%104, %469, %471) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:31
                   = prim::RaiseException(%msg.3, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:755:24
                  -> ()
                block1():
                  -> ()
              -> (%454)
            block1():
              %473 : Tensor = prim::TupleIndex(%454, %120)
              %474 : int = aten::dim(%473) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
              %475 : bool = aten::ne(%474, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
              %476 : bool = prim::If(%475) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
                block0():
                  -> (%117)
                block1():
                  %477 : Tensor = prim::TupleIndex(%454, %125)
                  %478 : int = aten::dim(%477) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:43
                  %479 : bool = aten::ne(%478, %122) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:43
                  -> (%479)
               = prim::If(%476) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:20
                block0():
                  %480 : Tensor = prim::TupleIndex(%454, %120)
                  %481 : int = aten::dim(%480) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:32
                  %482 : Tensor = prim::TupleIndex(%454, %125)
                  %483 : int = aten::dim(%482) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:32
                  %msg0.3 : str = aten::format(%105, %481, %483) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:31
                   = prim::RaiseException(%msg0.3, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:760:24
                  -> ()
                block1():
                  -> ()
              %485 : Tensor = prim::TupleIndex(%454, %120)
              %486 : Tensor = aten::unsqueeze(%485, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:761:26
              %487 : Tensor = prim::TupleIndex(%454, %125)
              %488 : Tensor = aten::unsqueeze(%487, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:761:46
              %hx3.3 : (Tensor, Tensor) = prim::TupleConstruct(%486, %488)
              -> (%hx3.3)
          %490 : int = aten::dim(%input0.20) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
          %491 : bool = aten::ne(%490, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
           = prim::If(%491) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:8
            block0():
              %492 : int = aten::dim(%input0.20) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:203:40
              %493 : str = aten::format(%100, %103, %492) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
               = prim::RaiseException(%493, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:201:12
              -> ()
            block1():
              -> ()
          %494 : int = aten::size(%input0.20, %119) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:30
          %495 : bool = aten::ne(%102, %494) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:11
           = prim::If(%495) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:8
            block0():
              %496 : int = aten::size(%input0.20, %119) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:207:37
              %497 : str = aten::format(%101, %102, %496) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
               = prim::RaiseException(%497, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:205:12
              -> ()
            block1():
              -> ()
          %498 : Tensor = prim::TupleIndex(%hx2.2, %120)
          %mini_batch.6 : int = aten::size(%input0.20, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:213:25
          %500 : (int, int, int) = prim::TupleConstruct(%122, %mini_batch.6, %102)
          %501 : int[] = aten::size(%498) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
          %502 : int, %503 : int, %504 : int = prim::TupleUnpack(%500)
          %505 : int[] = prim::ListConstruct(%502, %503, %504)
          %506 : bool = aten::ne(%501, %505) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
           = prim::If(%506) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
            block0():
              %507 : int[] = aten::size(%498) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
              %508 : int[] = aten::list(%507) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
              %509 : str = aten::format(%99, %500, %508) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
               = prim::RaiseException(%509, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
              -> ()
            block1():
              -> ()
          %510 : Tensor = prim::TupleIndex(%hx2.2, %125)
          %mini_batch.8 : int = aten::size(%input0.20, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:679:25
          %512 : (int, int, int) = prim::TupleConstruct(%122, %mini_batch.8, %102)
          %513 : int[] = aten::size(%510) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
          %514 : int, %515 : int, %516 : int = prim::TupleUnpack(%512)
          %517 : int[] = prim::ListConstruct(%514, %515, %516)
          %518 : bool = aten::ne(%513, %517) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
           = prim::If(%518) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
            block0():
              %519 : int[] = aten::size(%510) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
              %520 : int[] = aten::list(%519) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
              %521 : str = aten::format(%98, %512, %520) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
               = prim::RaiseException(%521, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
              -> ()
            block1():
              -> ()
          %_flat_weights.3 : Tensor[] = prim::GetAttr[name="_flat_weights"](%rnn.2)
          %training.33 : bool = prim::GetAttr[name="training"](%rnn.2)
          %524 : Tensor, %525 : Tensor = prim::TupleUnpack(%hx2.2)
          %526 : Tensor[] = prim::ListConstruct(%524, %525)
          %527 : Tensor, %528 : Tensor, %529 : Tensor = aten::lstm(%input0.20, %526, %_flat_weights.3, %117, %122, %110, %training.33, %126, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:769:21
          %hidden.3 : (Tensor, Tensor) = prim::TupleConstruct(%528, %529)
          %531 : bool = aten::__not__(%is_batched.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:15
          %hidden0.2 : (Tensor, Tensor), %output.2 : Tensor = prim::If(%531) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:12
            block0():
              %output0.3 : Tensor = aten::squeeze(%527, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:782:25
              %535 : Tensor = aten::squeeze(%528, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:26
              %536 : Tensor = aten::squeeze(%529, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:48
              %hidden1.3 : (Tensor, Tensor) = prim::TupleConstruct(%535, %536)
              -> (%hidden1.3, %output0.3)
            block1():
              -> (%hidden.3, %527)
          %538 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output.2, %hidden0.2)
          %x1.15 : Tensor, %540 : (Tensor, Tensor) = prim::TupleUnpack(%538)
          %h1.1 : Tensor, %c1.1 : Tensor = prim::TupleUnpack(%540)
          -> (%x1.15, %h1.1, %c1.1)
        block1():
          %rnn.4 : __torch__.torch.nn.modules.rnn.LSTM = prim::GetAttr[name="rnn"](%decoder.3)
          %544 : int[] = prim::ListConstruct(%120, %122, %125)
          %545 : Tensor = aten::permute(%x3.4, %544) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:237:33
          %546 : int = aten::dim(%545) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
          %is_batched.5 : bool = aten::eq(%546, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
          %548 : bool = aten::__not__(%is_batched.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:15
          %input0.24 : Tensor = prim::If(%548) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:12
            block0():
              %input0.26 : Tensor = aten::unsqueeze(%545, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:734:24
              -> (%input0.26)
            block1():
              -> (%545)
          %max_batch_size.2 : int = aten::size(%input0.24, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:735:29
          %552 : int = prim::dtype(%input0.24) # :0:0
          %553 : Device = prim::device(%input0.24) # :0:0
          %554 : int[] = prim::ListConstruct(%122, %max_batch_size.2, %102)
          %h_zeros.2 : Tensor = aten::zeros(%554, %552, %127, %553, %127) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:742:22
          %556 : int = prim::dtype(%input0.24) # :0:0
          %557 : Device = prim::device(%input0.24) # :0:0
          %558 : int[] = prim::ListConstruct(%122, %max_batch_size.2, %102)
          %c_zeros.2 : Tensor = aten::zeros(%558, %556, %127, %557, %127) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:745:22
          %hx0.2 : (Tensor, Tensor) = prim::TupleConstruct(%h_zeros.2, %c_zeros.2)
          %561 : int = aten::dim(%input0.24) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
          %562 : bool = aten::ne(%561, %103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
           = prim::If(%562) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:8
            block0():
              %563 : int = aten::dim(%input0.24) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:203:40
              %564 : str = aten::format(%100, %103, %563) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
               = prim::RaiseException(%564, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:201:12
              -> ()
            block1():
              -> ()
          %565 : int = aten::size(%input0.24, %119) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:30
          %566 : bool = aten::ne(%102, %565) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:11
           = prim::If(%566) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:8
            block0():
              %567 : int = aten::size(%input0.24, %119) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:207:37
              %568 : str = aten::format(%101, %102, %567) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
               = prim::RaiseException(%568, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:205:12
              -> ()
            block1():
              -> ()
          %569 : Tensor = prim::TupleIndex(%hx0.2, %120)
          %mini_batch.10 : int = aten::size(%input0.24, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:213:25
          %571 : (int, int, int) = prim::TupleConstruct(%122, %mini_batch.10, %102)
          %572 : int[] = aten::size(%569) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
          %573 : int, %574 : int, %575 : int = prim::TupleUnpack(%571)
          %576 : int[] = prim::ListConstruct(%573, %574, %575)
          %577 : bool = aten::ne(%572, %576) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
           = prim::If(%577) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
            block0():
              %578 : int[] = aten::size(%569) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
              %579 : int[] = aten::list(%578) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
              %580 : str = aten::format(%99, %571, %579) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
               = prim::RaiseException(%580, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
              -> ()
            block1():
              -> ()
          %581 : Tensor = prim::TupleIndex(%hx0.2, %125)
          %mini_batch.12 : int = aten::size(%input0.24, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:679:25
          %583 : (int, int, int) = prim::TupleConstruct(%122, %mini_batch.12, %102)
          %584 : int[] = aten::size(%581) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
          %585 : int, %586 : int, %587 : int = prim::TupleUnpack(%583)
          %588 : int[] = prim::ListConstruct(%585, %586, %587)
          %589 : bool = aten::ne(%584, %588) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
           = prim::If(%589) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
            block0():
              %590 : int[] = aten::size(%581) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
              %591 : int[] = aten::list(%590) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
              %592 : str = aten::format(%98, %583, %591) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
               = prim::RaiseException(%592, %106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
              -> ()
            block1():
              -> ()
          %_flat_weights.5 : Tensor[] = prim::GetAttr[name="_flat_weights"](%rnn.4)
          %training.35 : bool = prim::GetAttr[name="training"](%rnn.4)
          %595 : Tensor, %596 : Tensor = prim::TupleUnpack(%hx0.2)
          %597 : Tensor[] = prim::ListConstruct(%595, %596)
          %598 : Tensor, %599 : Tensor, %600 : Tensor = aten::lstm(%input0.24, %597, %_flat_weights.5, %117, %122, %110, %training.35, %126, %117) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:769:21
          %hidden.5 : (Tensor, Tensor) = prim::TupleConstruct(%599, %600)
          %602 : bool = aten::__not__(%is_batched.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:15
          %hidden0.4 : (Tensor, Tensor), %output.4 : Tensor = prim::If(%602) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:12
            block0():
              %output0.5 : Tensor = aten::squeeze(%598, %120) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:782:25
              %606 : Tensor = aten::squeeze(%599, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:26
              %607 : Tensor = aten::squeeze(%600, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:48
              %hidden1.5 : (Tensor, Tensor) = prim::TupleConstruct(%606, %607)
              -> (%hidden1.5, %output0.5)
            block1():
              -> (%hidden.5, %598)
          %609 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output.4, %hidden0.4)
          %x2.2 : Tensor, %611 : (Tensor, Tensor) = prim::TupleUnpack(%609)
          %h2.2 : Tensor, %c2.2 : Tensor = prim::TupleUnpack(%611)
          -> (%x2.2, %h2.2, %c2.2)
      %614 : int[] = prim::ListConstruct(%120, %122, %125)
      %x3.5 : Tensor = aten::permute(%x0, %614) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:239:12
      %decoder.5 : __torch__.torch.nn.modules.container.___torch_mangle_26.Sequential = prim::GetAttr[name="decoder"](%decoder.3)
      %_1.22 : __torch__.torch.nn.modules.conv.___torch_mangle_25.Conv1d = prim::GetAttr[name="1"](%decoder.5)
      %input0.28 : Tensor = aten::relu(%x3.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
      %weight.51 : Tensor = prim::GetAttr[name="weight"](%_1.22)
      %bias.51 : Tensor? = prim::GetAttr[name="bias"](%_1.22)
      %621 : int[] = prim::ListConstruct(%125)
      %622 : int[] = prim::ListConstruct(%120)
      %623 : int[] = prim::ListConstruct(%125)
      %input1.15 : Tensor = aten::conv1d(%input0.28, %weight.51, %bias.51, %621, %622, %623, %125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
      %x4.3 : Tensor = aten::sigmoid(%input1.15) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py:290:15
      %626 : (Tensor, Tensor, Tensor) = prim::TupleConstruct(%x4.3, %h0, %c0)
      %x4.2 : Tensor, %h0.2 : Tensor, %c0.2 : Tensor = prim::TupleUnpack(%626)
      %630 : Tensor = aten::squeeze(%x4.2, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
      %631 : int[] = prim::ListConstruct(%125)
      %632 : Tensor = aten::mean(%630, %631, %126, %127) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
      %out.2 : Tensor = aten::unsqueeze(%632, %125) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
      %634 : (Tensor, Tensor, Tensor) = prim::TupleConstruct(%out.2, %h0.2, %c0.2)
      %out0.1 : Tensor, %35 : Tensor, %36 : Tensor = prim::TupleUnpack(%634)
       = prim::SetAttr[name="_h"](%self.1, %35)
       = prim::SetAttr[name="_c"](%self.1, %36)
      -> (%out0.1)
    block1():
      %37 : bool = aten::eq(%sr0.1, %8) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:378:13
      %out1 : Tensor = prim::If(%37) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:378:8
        block0():
          %_model_8k.1 : __torch__.vad.model.vad_annotator.VADRNNJIT = prim::GetAttr[name="_model_8k"](%self.1)
          %_h.5 : Tensor = prim::GetAttr[name="_h"](%self.1)
          %_c : Tensor = prim::GetAttr[name="_c"](%self.1)
          %635 : str = prim::Constant[value="Expected hidden[1] size {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:696:31
          %636 : str = prim::Constant[value="Expected hidden[0] size {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:694:31
          %637 : str = prim::Constant[value="input must have {} dimensions, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
          %638 : str = prim::Constant[value="input.size(-1) must be equal to input_size. Expected {}, got {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
          %639 : int = prim::Constant[value=64]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:741:73
          %640 : int = prim::Constant[value=3]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:40
          %641 : str = prim::Constant[value="For batched 3-D input, hx and cx should also be 3-D but got ({}-D, {}-D) tensors"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:31
          %642 : str = prim::Constant[value="For unbatched 2-D input, hx and cx should also be 2-D but got ({}-D, {}-D) tensors"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:31
          %643 : str = prim::Constant[value="builtins.RuntimeError"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:755:30
          %644 : str = prim::Constant[value="Expected more than 1 value per channel when training, got input size {}"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
          %645 : str = prim::Constant[value="builtins.ValueError"]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:298:18
          %646 : float = prim::Constant[value=1.0000000000000001e-05]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:179:12
          %647 : float = prim::Constant[value=0.10000000000000001]() # :0:0
          %648 : int = prim::Constant[value=16]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
          %649 : int = prim::Constant[value=32]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
          %650 : int = prim::Constant[value=258]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:304:53
          %651 : float = prim::Constant[value=0.14999999999999999]() # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/dropout.py:58:32
          %652 : int[] = prim::Constant[value=[0]]()
          %653 : Function = prim::Constant[name="simple_pad"]()
          %654 : bool = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:409:41
          %655 : int = prim::Constant[value=1048576]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:36
          %656 : int = prim::Constant[value=-1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:412:34
          %657 : int = prim::Constant[value=0]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:38:43
          %658 : int = prim::Constant[value=6]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
          %659 : int = prim::Constant[value=2]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:62
          %660 : str = prim::Constant[value="reflect"]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:81
          %661 : int[] = prim::Constant[value=[1]]()
          %662 : int = prim::Constant[value=1]() # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:294:40
          %663 : bool = prim::Constant[value=0]()
          %664 : NoneType = prim::Constant()
          %feature_extractor.1 : __torch__.vad.utils.pytorch_stft.___torch_mangle_1.STFT = prim::GetAttr[name="feature_extractor"](%_model_8k.1)
          %num_batches.1 : int = aten::size(%x0.3, %657) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:41:22
          %num_samples.1 : int = aten::size(%x0.3, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:42:22
          %668 : int[] = prim::ListConstruct(%num_batches.1, %662, %num_samples.1)
          %input_data0.1 : Tensor = aten::view(%x0.3, %668) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:44:21
          %filter_length.1 : int = prim::GetAttr[name="filter_length"](%feature_extractor.1)
          %hop_length.1 : int = prim::GetAttr[name="hop_length"](%feature_extractor.1)
          %672 : int = aten::sub(%filter_length.1, %hop_length.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:22
          %673 : float = aten::div(%672, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:22
          %to_pad.2 : int = aten::Int(%673) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:46:17
          %675 : Tensor = aten::unsqueeze(%input_data0.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:27
          %676 : int[] = prim::ListConstruct(%to_pad.2, %to_pad.2, %657, %657)
          %input_data1.1 : Tensor = aten::pad(%675, %676, %660, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:47:21
          %input_data2.1 : Tensor = aten::squeeze(%input_data1.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:48:21
          %forward_basis_buffer.1 : Tensor = prim::GetAttr[name="forward_basis_buffer"](%feature_extractor.1)
          %hop_length : int = prim::GetAttr[name="hop_length"](%feature_extractor.1)
          %681 : int[] = prim::ListConstruct(%hop_length)
          %682 : int[] = prim::ListConstruct(%657)
          %forward_transform.1 : Tensor = aten::conv1d(%input_data2.1, %forward_basis_buffer.1, %664, %681, %682, %661, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:50:28
          %filter_length : int = prim::GetAttr[name="filter_length"](%feature_extractor.1)
          %685 : float = aten::div(%filter_length, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:22
          %686 : float = aten::add(%685, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:22
          %cutoff.1 : int = aten::Int(%686) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:56:17
          %688 : Tensor = aten::slice(%forward_transform.1, %657, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
          %689 : Tensor = aten::slice(%688, %662, %664, %cutoff.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
          %690 : Tensor = aten::slice(%689, %659, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
          %real_part.1 : Tensor = aten::to(%690, %658, %663, %663, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:57:20
          %692 : Tensor = aten::slice(%forward_transform.1, %657, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
          %693 : Tensor = aten::slice(%692, %662, %cutoff.1, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
          %694 : Tensor = aten::slice(%693, %659, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
          %imag_part.1 : Tensor = aten::to(%694, %658, %663, %663, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:58:20
          %696 : Tensor = aten::pow(%real_part.1, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:31
          %697 : Tensor = aten::pow(%imag_part.1, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:46
          %698 : Tensor = aten::add(%696, %697, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:31
          %magnitude.1 : Tensor = aten::sqrt(%698) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:60:20
          %700 : Tensor = prim::data(%imag_part.1) # :0:0
          %701 : Tensor = prim::data(%real_part.1) # :0:0
          %phase.1 : Tensor = aten::atan2(%700, %701) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/utils/pytorch_stft.py:61:16
          %703 : (Tensor, Tensor) = prim::TupleConstruct(%magnitude.1, %phase.1)
          %x0.6 : Tensor = prim::TupleIndex(%703, %657)
          %adaptive_normalization.1 : __torch__.models.stt_model_blocks.___torch_mangle_0.AdaptiveAudioNormalizationNew = prim::GetAttr[name="adaptive_normalization"](%_model_8k.1)
          %706 : Tensor = aten::mul(%x0.6, %655) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:28
          %spect0.1 : Tensor = aten::log1p(%706) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:406:16
          %708 : int[] = aten::size(%spect0.1) # <string>:13:9
          %709 : int = aten::len(%708) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:11
          %710 : bool = aten::eq(%709, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:11
          %spect1 : Tensor = prim::If(%710) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:407:8
            block0():
              %712 : Tensor = aten::unsqueeze(%spect0.1, %657) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
              %713 : Tensor = aten::slice(%712, %662, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
              %spect1.1 : Tensor = aten::slice(%713, %659, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:408:20
              -> (%spect1.1)
            block1():
              -> (%spect0.1)
          %715 : int[] = prim::ListConstruct(%662)
          %mean.1 : Tensor = aten::mean(%spect1, %715, %654, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:409:15
          %to_pad.1 : int = prim::GetAttr[name="to_pad"](%adaptive_normalization.1)
          %718 : Tensor = aten::slice(%mean.1, %657, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
          %719 : Tensor = aten::slice(%718, %662, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
          %720 : int = aten::add(%to_pad.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:37
          %721 : Tensor = aten::slice(%719, %659, %662, %720, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:26
          %722 : int[] = prim::ListConstruct(%656)
          %left_pad.1 : Tensor = aten::flip(%721, %722) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:392:15
          %724 : Tensor = aten::slice(%mean.1, %657, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
          %725 : Tensor = aten::slice(%724, %662, %664, %664, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
          %726 : int = aten::sub(%656, %to_pad.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:35
          %727 : Tensor = aten::slice(%725, %659, %726, %656, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:27
          %728 : int[] = prim::ListConstruct(%656)
          %right_pad.1 : Tensor = aten::flip(%727, %728) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:393:16
          %730 : Tensor[] = prim::ListConstruct(%left_pad.1, %mean.1, %right_pad.1)
          %mean0.1 : Tensor = aten::cat(%730, %659) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:394:11
          %filter_.1 : Tensor = prim::GetAttr[name="filter_"](%adaptive_normalization.1)
          %mean1.1 : Tensor = aten::conv1d(%mean0.1, %filter_.1, %664, %661, %652, %661, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:411:15
          %734 : int[] = prim::ListConstruct(%656)
          %mean_mean.1 : Tensor = aten::mean(%mean1.1, %734, %654, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:412:20
          %736 : Tensor = aten::neg(%mean_mean.1) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:413:26
          %norm.1 : Tensor = aten::add(%spect1, %736, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/stt_model_blocks.py:413:16
          %738 : Tensor[] = prim::ListConstruct(%x0.6, %norm.1)
          %x1.6 : Tensor = aten::cat(%738, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:294:12
          %first_layer.1 : __torch__.torch.nn.modules.container.___torch_mangle_3.Sequential = prim::GetAttr[name="first_layer"](%_model_8k.1)
          %_0.4 : __torch__.models.number_vad_model.___torch_mangle_4.ConvBlock = prim::GetAttr[name="0"](%first_layer.1)
          %_1.4 : __torch__.torch.nn.modules.dropout.___torch_mangle_12.Dropout = prim::GetAttr[name="1"](%first_layer.1)
          %pw_conv.3 : __torch__.torch.nn.modules.container.___torch_mangle_10.Sequential = prim::GetAttr[name="pw_conv"](%_0.4)
          %dw_conv.3 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="dw_conv"](%_0.4)
          %_0.6 : __torch__.torch.nn.modules.conv.___torch_mangle_7.Conv1d = prim::GetAttr[name="0"](%dw_conv.3)
          %_1.1 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity = prim::GetAttr[name="1"](%dw_conv.3)
          %_2 : __torch__.torch.nn.modules.activation.___torch_mangle_9.ReLU = prim::GetAttr[name="2"](%dw_conv.3)
          %weight.3 : Tensor = prim::GetAttr[name="weight"](%_0.6)
          %bias.3 : Tensor? = prim::GetAttr[name="bias"](%_0.6)
          %750 : int[] = prim::ListConstruct(%662)
          %751 : int[] = prim::ListConstruct(%659)
          %752 : int[] = prim::ListConstruct(%662)
          %input1.2 : Tensor = aten::conv1d(%x1.6, %weight.3, %bias.3, %750, %751, %752, %650) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %result.6 : Tensor = aten::relu(%input1.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.8 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv1d = prim::GetAttr[name="0"](%pw_conv.3)
          %_1.6 : __torch__.torch.nn.modules.linear.___torch_mangle_8.Identity = prim::GetAttr[name="1"](%pw_conv.3)
          %weight.5 : Tensor = prim::GetAttr[name="weight"](%_0.8)
          %bias.5 : Tensor? = prim::GetAttr[name="bias"](%_0.8)
          %759 : int[] = prim::ListConstruct(%662)
          %760 : int[] = prim::ListConstruct(%657)
          %761 : int[] = prim::ListConstruct(%662)
          %x0.8 : Tensor = aten::conv1d(%result.6, %weight.5, %bias.5, %759, %760, %761, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %proj.3 : __torch__.torch.nn.modules.conv.___torch_mangle_11.Conv1d = prim::GetAttr[name="proj"](%_0.4)
          %weight.7 : Tensor = prim::GetAttr[name="weight"](%proj.3)
          %bias.7 : Tensor? = prim::GetAttr[name="bias"](%proj.3)
          %766 : int[] = prim::ListConstruct(%662)
          %767 : int[] = prim::ListConstruct(%657)
          %768 : int[] = prim::ListConstruct(%662)
          %residual.3 : Tensor = aten::conv1d(%x1.6, %weight.7, %bias.7, %766, %767, %768, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %x1.8 : Tensor = aten::add_(%x0.8, %residual.3, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
          %activation.1 : __torch__.torch.nn.modules.activation.___torch_mangle_9.ReLU = prim::GetAttr[name="activation"](%_0.4)
          %input0.5 : Tensor = aten::relu(%x1.8) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %training.3 : bool = prim::GetAttr[name="training"](%_1.4)
          %x2.1 : Tensor = aten::dropout(%input0.5, %651, %training.3) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
          %encoder.1 : __torch__.torch.nn.modules.container.___torch_mangle_24.Sequential = prim::GetAttr[name="encoder"](%_model_8k.1)
          %_0.3 : __torch__.torch.nn.modules.conv.___torch_mangle_13.Conv1d = prim::GetAttr[name="0"](%encoder.1)
          %_1.3 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_14.BatchNorm1d = prim::GetAttr[name="1"](%encoder.1)
          %_3 : __torch__.torch.nn.modules.container.___torch_mangle_16.Sequential = prim::GetAttr[name="3"](%encoder.1)
          %_4 : __torch__.torch.nn.modules.conv.___torch_mangle_23.Conv1d = prim::GetAttr[name="4"](%encoder.1)
          %_5 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_24.BatchNorm1d = prim::GetAttr[name="5"](%encoder.1)
          %_7 : __torch__.torch.nn.modules.container.___torch_mangle_25.Sequential = prim::GetAttr[name="7"](%encoder.1)
          %_8 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv1d = prim::GetAttr[name="8"](%encoder.1)
          %_9 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_24.BatchNorm1d = prim::GetAttr[name="9"](%encoder.1)
          %_11 : __torch__.torch.nn.modules.container.___torch_mangle_32.Sequential = prim::GetAttr[name="11"](%encoder.1)
          %_12 : __torch__.torch.nn.modules.conv.___torch_mangle_36.Conv1d = prim::GetAttr[name="12"](%encoder.1)
          %_13 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_37.BatchNorm1d = prim::GetAttr[name="13"](%encoder.1)
          %weight.6 : Tensor = prim::GetAttr[name="weight"](%_0.3)
          %bias.6 : Tensor? = prim::GetAttr[name="bias"](%_0.3)
          %789 : int[] = prim::ListConstruct(%659)
          %790 : int[] = prim::ListConstruct(%657)
          %791 : int[] = prim::ListConstruct(%662)
          %input0.7 : Tensor = aten::conv1d(%x2.1, %weight.6, %bias.6, %789, %790, %791, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %training.5 : bool = prim::GetAttr[name="training"](%_1.3)
           = prim::If(%training.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
            block0():
              %num_batches_tracked.2 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_1.3)
              %795 : Tensor = aten::add_(%num_batches_tracked.2, %662, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
              -> ()
            block1():
              -> ()
          %training.6 : bool = prim::GetAttr[name="training"](%_1.3)
          %running_mean.2 : Tensor = prim::GetAttr[name="running_mean"](%_1.3)
          %running_var.2 : Tensor = prim::GetAttr[name="running_var"](%_1.3)
          %weight.8 : Tensor = prim::GetAttr[name="weight"](%_1.3)
          %bias.8 : Tensor = prim::GetAttr[name="bias"](%_1.3)
           = prim::If(%training.6) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
            block0():
              %801 : int[] = aten::size(%input0.7) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
              %size_prods.2 : int = aten::__getitem__(%801, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
              %803 : int = aten::len(%801) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %804 : int = aten::sub(%803, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %size_prods0.1 : int = prim::Loop(%804, %654, %size_prods.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
                block0(%i.2 : int, %size_prods0.8 : int):
                  %808 : int = aten::add(%i.2, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
                  %809 : int = aten::__getitem__(%801, %808) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
                  %size_prods1.2 : int = aten::mul(%size_prods0.8, %809) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
                  -> (%654, %size_prods1.2)
              %811 : bool = aten::eq(%size_prods0.1, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
               = prim::If(%811) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
                block0():
                  %812 : str = aten::format(%644, %801) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
                   = prim::RaiseException(%812, %645) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
                  -> ()
                block1():
                  -> ()
              -> ()
            block1():
              -> ()
          %input1.4 : Tensor = aten::batch_norm(%input0.7, %weight.8, %bias.8, %running_mean.2, %running_var.2, %training.6, %647, %646, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
          %input2.1 : Tensor = aten::relu(%input1.4) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.5 : __torch__.models.number_vad_model.___torch_mangle_17.ConvBlock = prim::GetAttr[name="0"](%_3)
          %_1.5 : __torch__.torch.nn.modules.dropout.___torch_mangle_12.Dropout = prim::GetAttr[name="1"](%_3)
          %pw_conv.2 : __torch__.torch.nn.modules.container.___torch_mangle_20.Sequential = prim::GetAttr[name="pw_conv"](%_0.5)
          %dw_conv.2 : __torch__.torch.nn.modules.container.___torch_mangle_18.Sequential = prim::GetAttr[name="dw_conv"](%_0.5)
          %_0.7 : __torch__.torch.nn.modules.conv.___torch_mangle_19.Conv1d = prim::GetAttr[name="0"](%dw_conv.2)
          %weight.14 : Tensor = prim::GetAttr[name="weight"](%_0.7)
          %bias.14 : Tensor? = prim::GetAttr[name="bias"](%_0.7)
          %822 : int[] = prim::ListConstruct(%662)
          %823 : int[] = prim::ListConstruct(%659)
          %824 : int[] = prim::ListConstruct(%662)
          %input1.6 : Tensor = aten::conv1d(%input2.1, %weight.14, %bias.14, %822, %823, %824, %648) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %result.5 : Tensor = aten::relu(%input1.6) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.9 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv1d = prim::GetAttr[name="0"](%pw_conv.2)
          %weight.24 : Tensor = prim::GetAttr[name="weight"](%_0.9)
          %bias.24 : Tensor? = prim::GetAttr[name="bias"](%_0.9)
          %830 : int[] = prim::ListConstruct(%662)
          %831 : int[] = prim::ListConstruct(%657)
          %832 : int[] = prim::ListConstruct(%662)
          %x0.2 : Tensor = aten::conv1d(%result.5, %weight.24, %bias.24, %830, %831, %832, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %proj.2 : __torch__.torch.nn.modules.conv.___torch_mangle_21.Conv1d = prim::GetAttr[name="proj"](%_0.5)
          %weight.10 : Tensor = prim::GetAttr[name="weight"](%proj.2)
          %bias.10 : Tensor? = prim::GetAttr[name="bias"](%proj.2)
          %837 : int[] = prim::ListConstruct(%662)
          %838 : int[] = prim::ListConstruct(%657)
          %839 : int[] = prim::ListConstruct(%662)
          %residual.2 : Tensor = aten::conv1d(%input2.1, %weight.10, %bias.10, %837, %838, %839, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %x1.2 : Tensor = aten::add_(%x0.2, %residual.2, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
          %input0.9 : Tensor = aten::relu(%x1.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %training.4 : bool = prim::GetAttr[name="training"](%_1.5)
          %input3.1 : Tensor = aten::dropout(%input0.9, %651, %training.4) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
          %weight.12 : Tensor = prim::GetAttr[name="weight"](%_4)
          %bias.12 : Tensor? = prim::GetAttr[name="bias"](%_4)
          %847 : int[] = prim::ListConstruct(%659)
          %848 : int[] = prim::ListConstruct(%657)
          %849 : int[] = prim::ListConstruct(%662)
          %input4.1 : Tensor = aten::conv1d(%input3.1, %weight.12, %bias.12, %847, %848, %849, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %training.8 : bool = prim::GetAttr[name="training"](%_5)
           = prim::If(%training.8) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
            block0():
              %num_batches_tracked.4 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_5)
              %853 : Tensor = aten::add_(%num_batches_tracked.4, %662, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
              -> ()
            block1():
              -> ()
          %training.12 : bool = prim::GetAttr[name="training"](%_5)
          %running_mean.4 : Tensor = prim::GetAttr[name="running_mean"](%_5)
          %running_var.4 : Tensor = prim::GetAttr[name="running_var"](%_5)
          %weight.16 : Tensor = prim::GetAttr[name="weight"](%_5)
          %bias.16 : Tensor = prim::GetAttr[name="bias"](%_5)
           = prim::If(%training.12) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
            block0():
              %859 : int[] = aten::size(%input4.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
              %size_prods.4 : int = aten::__getitem__(%859, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
              %861 : int = aten::len(%859) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %862 : int = aten::sub(%861, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %size_prods0.10 : int = prim::Loop(%862, %654, %size_prods.4) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
                block0(%i.4 : int, %size_prods0.12 : int):
                  %866 : int = aten::add(%i.4, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
                  %867 : int = aten::__getitem__(%859, %866) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
                  %size_prods1.4 : int = aten::mul(%size_prods0.12, %867) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
                  -> (%654, %size_prods1.4)
              %869 : bool = aten::eq(%size_prods0.10, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
               = prim::If(%869) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
                block0():
                  %870 : str = aten::format(%644, %859) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
                   = prim::RaiseException(%870, %645) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
                  -> ()
                block1():
                  -> ()
              -> ()
            block1():
              -> ()
          %input5.1 : Tensor = aten::batch_norm(%input4.1, %weight.16, %bias.16, %running_mean.4, %running_var.4, %training.12, %647, %646, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
          %input6.1 : Tensor = aten::relu(%input5.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.11 : __torch__.models.number_vad_model.___torch_mangle_26.ConvBlock = prim::GetAttr[name="0"](%_7)
          %_1.11 : __torch__.torch.nn.modules.dropout.___torch_mangle_12.Dropout = prim::GetAttr[name="1"](%_7)
          %pw_conv.4 : __torch__.torch.nn.modules.container.___torch_mangle_30.Sequential = prim::GetAttr[name="pw_conv"](%_0.11)
          %dw_conv.4 : __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential = prim::GetAttr[name="dw_conv"](%_0.11)
          %_0.13 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv1d = prim::GetAttr[name="0"](%dw_conv.4)
          %weight.22 : Tensor = prim::GetAttr[name="weight"](%_0.13)
          %bias.22 : Tensor? = prim::GetAttr[name="bias"](%_0.13)
          %880 : int[] = prim::ListConstruct(%662)
          %881 : int[] = prim::ListConstruct(%659)
          %882 : int[] = prim::ListConstruct(%662)
          %input1.8 : Tensor = aten::conv1d(%input6.1, %weight.22, %bias.22, %880, %881, %882, %649) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %result.7 : Tensor = aten::relu(%input1.8) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.15 : __torch__.torch.nn.modules.conv.___torch_mangle_31.Conv1d = prim::GetAttr[name="0"](%pw_conv.4)
          %weight.18 : Tensor = prim::GetAttr[name="weight"](%_0.15)
          %bias.18 : Tensor? = prim::GetAttr[name="bias"](%_0.15)
          %888 : int[] = prim::ListConstruct(%662)
          %889 : int[] = prim::ListConstruct(%657)
          %890 : int[] = prim::ListConstruct(%662)
          %x0.4 : Tensor = aten::conv1d(%result.7, %weight.18, %bias.18, %888, %889, %890, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %x1.4 : Tensor = aten::add_(%x0.4, %input6.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
          %input0.8 : Tensor = aten::relu(%x1.4) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %training.10 : bool = prim::GetAttr[name="training"](%_1.11)
          %input7.1 : Tensor = aten::dropout(%input0.8, %651, %training.10) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
          %weight.20 : Tensor = prim::GetAttr[name="weight"](%_8)
          %bias.20 : Tensor? = prim::GetAttr[name="bias"](%_8)
          %898 : int[] = prim::ListConstruct(%662)
          %899 : int[] = prim::ListConstruct(%657)
          %900 : int[] = prim::ListConstruct(%662)
          %input8.1 : Tensor = aten::conv1d(%input7.1, %weight.20, %bias.20, %898, %899, %900, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %training.14 : bool = prim::GetAttr[name="training"](%_9)
           = prim::If(%training.14) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
            block0():
              %num_batches_tracked.6 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_9)
              %904 : Tensor = aten::add_(%num_batches_tracked.6, %662, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
              -> ()
            block1():
              -> ()
          %training.18 : bool = prim::GetAttr[name="training"](%_9)
          %running_mean.6 : Tensor = prim::GetAttr[name="running_mean"](%_9)
          %running_var.6 : Tensor = prim::GetAttr[name="running_var"](%_9)
          %weight.26 : Tensor = prim::GetAttr[name="weight"](%_9)
          %bias.26 : Tensor = prim::GetAttr[name="bias"](%_9)
           = prim::If(%training.18) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
            block0():
              %910 : int[] = aten::size(%input8.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
              %size_prods.6 : int = aten::__getitem__(%910, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
              %912 : int = aten::len(%910) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %913 : int = aten::sub(%912, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %size_prods0.14 : int = prim::Loop(%913, %654, %size_prods.6) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
                block0(%i.6 : int, %size_prods0.16 : int):
                  %917 : int = aten::add(%i.6, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
                  %918 : int = aten::__getitem__(%910, %917) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
                  %size_prods1.6 : int = aten::mul(%size_prods0.16, %918) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
                  -> (%654, %size_prods1.6)
              %920 : bool = aten::eq(%size_prods0.14, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
               = prim::If(%920) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
                block0():
                  %921 : str = aten::format(%644, %910) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
                   = prim::RaiseException(%921, %645) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
                  -> ()
                block1():
                  -> ()
              -> ()
            block1():
              -> ()
          %input9.1 : Tensor = aten::batch_norm(%input8.1, %weight.26, %bias.26, %running_mean.6, %running_var.6, %training.18, %647, %646, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
          %input10.1 : Tensor = aten::relu(%input9.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0.2 : __torch__.models.number_vad_model.___torch_mangle_33.ConvBlock = prim::GetAttr[name="0"](%_11)
          %_1.2 : __torch__.torch.nn.modules.dropout.___torch_mangle_12.Dropout = prim::GetAttr[name="1"](%_11)
          %pw_conv.1 : __torch__.torch.nn.modules.container.___torch_mangle_34.Sequential = prim::GetAttr[name="pw_conv"](%_0.2)
          %dw_conv.1 : __torch__.torch.nn.modules.container.___torch_mangle_28.Sequential = prim::GetAttr[name="dw_conv"](%_0.2)
          %_0.1 : __torch__.torch.nn.modules.conv.___torch_mangle_29.Conv1d = prim::GetAttr[name="0"](%dw_conv.1)
          %weight.2 : Tensor = prim::GetAttr[name="weight"](%_0.1)
          %bias.2 : Tensor? = prim::GetAttr[name="bias"](%_0.1)
          %931 : int[] = prim::ListConstruct(%662)
          %932 : int[] = prim::ListConstruct(%659)
          %933 : int[] = prim::ListConstruct(%662)
          %input1.5 : Tensor = aten::conv1d(%input10.1, %weight.2, %bias.2, %931, %932, %933, %649) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %result.4 : Tensor = aten::relu(%input1.5) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %_0 : __torch__.torch.nn.modules.conv.___torch_mangle_35.Conv1d = prim::GetAttr[name="0"](%pw_conv.1)
          %weight.4 : Tensor = prim::GetAttr[name="weight"](%_0)
          %bias.4 : Tensor? = prim::GetAttr[name="bias"](%_0)
          %939 : int[] = prim::ListConstruct(%662)
          %940 : int[] = prim::ListConstruct(%657)
          %941 : int[] = prim::ListConstruct(%662)
          %x0.1 : Tensor = aten::conv1d(%result.4, %weight.4, %bias.4, %939, %940, %941, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %proj.1 : __torch__.torch.nn.modules.conv.___torch_mangle_35.Conv1d = prim::GetAttr[name="proj"](%_0.2)
          %weight.28 : Tensor = prim::GetAttr[name="weight"](%proj.1)
          %bias.28 : Tensor? = prim::GetAttr[name="bias"](%proj.1)
          %946 : int[] = prim::ListConstruct(%662)
          %947 : int[] = prim::ListConstruct(%657)
          %948 : int[] = prim::ListConstruct(%662)
          %residual.1 : Tensor = aten::conv1d(%input10.1, %weight.28, %bias.28, %946, %947, %948, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %x1.1 : Tensor = aten::add_(%x0.1, %residual.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/models/number_vad_model.py:110:8
          %input0.11 : Tensor = aten::relu(%x1.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %training.16 : bool = prim::GetAttr[name="training"](%_1.2)
          %input11.1 : Tensor = aten::dropout(%input0.11, %651, %training.16) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1252:60
          %weight.30 : Tensor = prim::GetAttr[name="weight"](%_12)
          %bias.30 : Tensor? = prim::GetAttr[name="bias"](%_12)
          %956 : int[] = prim::ListConstruct(%662)
          %957 : int[] = prim::ListConstruct(%657)
          %958 : int[] = prim::ListConstruct(%662)
          %input12.1 : Tensor = aten::conv1d(%input11.1, %weight.30, %bias.30, %956, %957, %958, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %training.7 : bool = prim::GetAttr[name="training"](%_13)
           = prim::If(%training.7) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:145:11
            block0():
              %num_batches_tracked.1 : Tensor = prim::GetAttr[name="num_batches_tracked"](%_13)
              %962 : Tensor = aten::add_(%num_batches_tracked.1, %662, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py:148:16
              -> ()
            block1():
              -> ()
          %training : bool = prim::GetAttr[name="training"](%_13)
          %running_mean.1 : Tensor = prim::GetAttr[name="running_mean"](%_13)
          %running_var.1 : Tensor = prim::GetAttr[name="running_var"](%_13)
          %weight.9 : Tensor = prim::GetAttr[name="weight"](%_13)
          %bias.9 : Tensor = prim::GetAttr[name="bias"](%_13)
           = prim::If(%training) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2435:4
            block0():
              %968 : int[] = aten::size(%input12.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2436:27
              %size_prods.1 : int = aten::__getitem__(%968, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2400:17
              %970 : int = aten::len(%968) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %971 : int = aten::sub(%970, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:19
              %size_prods0 : int = prim::Loop(%971, %654, %size_prods.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2401:4
                block0(%i.1 : int, %size_prods0.7 : int):
                  %975 : int = aten::add(%i.1, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:27
                  %976 : int = aten::__getitem__(%968, %975) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:22
                  %size_prods1.1 : int = aten::mul(%size_prods0.7, %976) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2402:8
                  -> (%654, %size_prods1.1)
              %978 : bool = aten::eq(%size_prods0, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:7
               = prim::If(%978) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2403:4
                block0():
                  %979 : str = aten::format(%644, %968) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:25
                   = prim::RaiseException(%979, %645) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2404:8
                  -> ()
                block1():
                  -> ()
              -> ()
            block1():
              -> ()
          %input13.1 : Tensor = aten::batch_norm(%input12.1, %weight.9, %bias.9, %running_mean.1, %running_var.1, %training, %647, %646, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:2438:11
          %x3.1 : Tensor = aten::relu(%input13.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %decoder.2 : __torch__.vad.model.vad_annotator.___torch_mangle_38.VADDecoderRNNJIT = prim::GetAttr[name="decoder"](%_model_8k.1)
          %983 : int = aten::len(%_h.5) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:11
          %984 : bool = aten::Bool(%983) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:11
          %x8 : Tensor, %h1 : Tensor, %c1 : Tensor = prim::If(%984) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:234:8
            block0():
              %rnn.1 : __torch__.torch.nn.modules.rnn.___torch_mangle_39.LSTM = prim::GetAttr[name="rnn"](%decoder.2)
              %989 : int[] = prim::ListConstruct(%657, %659, %662)
              %990 : Tensor = aten::permute(%x3.1, %989) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:235:33
              %991 : (Tensor, Tensor) = prim::TupleConstruct(%_h.5, %_c)
              %992 : int = aten::dim(%990) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
              %is_batched.2 : bool = aten::eq(%992, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
              %994 : bool = aten::__not__(%is_batched.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:15
              %input0.2 : Tensor = prim::If(%994) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:12
                block0():
                  %input0.4 : Tensor = aten::unsqueeze(%990, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:734:24
                  -> (%input0.4)
                block1():
                  -> (%990)
              %hx2.1 : (Tensor, Tensor) = prim::If(%is_batched.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:751:16
                block0():
                  %998 : Tensor = prim::TupleIndex(%991, %657)
                  %999 : int = aten::dim(%998) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
                  %1000 : bool = aten::ne(%999, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
                  %1001 : bool = prim::If(%1000) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:24
                    block0():
                      -> (%654)
                    block1():
                      %1002 : Tensor = prim::TupleIndex(%991, %662)
                      %1003 : int = aten::dim(%1002) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:44
                      %1004 : bool = aten::ne(%1003, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:44
                      -> (%1004)
                   = prim::If(%1001) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:752:20
                    block0():
                      %1005 : Tensor = prim::TupleIndex(%991, %657)
                      %1006 : int = aten::dim(%1005) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:32
                      %1007 : Tensor = prim::TupleIndex(%991, %662)
                      %1008 : int = aten::dim(%1007) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:32
                      %msg.2 : str = aten::format(%641, %1006, %1008) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:753:31
                       = prim::RaiseException(%msg.2, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:755:24
                      -> ()
                    block1():
                      -> ()
                  -> (%991)
                block1():
                  %1010 : Tensor = prim::TupleIndex(%991, %657)
                  %1011 : int = aten::dim(%1010) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
                  %1012 : bool = aten::ne(%1011, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
                  %1013 : bool = prim::If(%1012) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:23
                    block0():
                      -> (%654)
                    block1():
                      %1014 : Tensor = prim::TupleIndex(%991, %662)
                      %1015 : int = aten::dim(%1014) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:43
                      %1016 : bool = aten::ne(%1015, %659) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:43
                      -> (%1016)
                   = prim::If(%1013) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:757:20
                    block0():
                      %1017 : Tensor = prim::TupleIndex(%991, %657)
                      %1018 : int = aten::dim(%1017) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:32
                      %1019 : Tensor = prim::TupleIndex(%991, %662)
                      %1020 : int = aten::dim(%1019) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:32
                      %msg0.2 : str = aten::format(%642, %1018, %1020) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:758:31
                       = prim::RaiseException(%msg0.2, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:760:24
                      -> ()
                    block1():
                      -> ()
                  %1022 : Tensor = prim::TupleIndex(%991, %657)
                  %1023 : Tensor = aten::unsqueeze(%1022, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:761:26
                  %1024 : Tensor = prim::TupleIndex(%991, %662)
                  %1025 : Tensor = aten::unsqueeze(%1024, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:761:46
                  %hx3.2 : (Tensor, Tensor) = prim::TupleConstruct(%1023, %1025)
                  -> (%hx3.2)
              %1027 : int = aten::dim(%input0.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
              %1028 : bool = aten::ne(%1027, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
               = prim::If(%1028) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:8
                block0():
                  %1029 : int = aten::dim(%input0.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:203:40
                  %1030 : str = aten::format(%637, %640, %1029) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
                   = prim::RaiseException(%1030, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:201:12
                  -> ()
                block1():
                  -> ()
              %1031 : int = aten::size(%input0.2, %656) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:30
              %1032 : bool = aten::ne(%639, %1031) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:11
               = prim::If(%1032) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:8
                block0():
                  %1033 : int = aten::size(%input0.2, %656) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:207:37
                  %1034 : str = aten::format(%638, %639, %1033) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
                   = prim::RaiseException(%1034, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:205:12
                  -> ()
                block1():
                  -> ()
              %1035 : Tensor = prim::TupleIndex(%hx2.1, %657)
              %mini_batch.5 : int = aten::size(%input0.2, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:213:25
              %1037 : (int, int, int) = prim::TupleConstruct(%659, %mini_batch.5, %639)
              %1038 : int[] = aten::size(%1035) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
              %1039 : int, %1040 : int, %1041 : int = prim::TupleUnpack(%1037)
              %1042 : int[] = prim::ListConstruct(%1039, %1040, %1041)
              %1043 : bool = aten::ne(%1038, %1042) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
               = prim::If(%1043) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
                block0():
                  %1044 : int[] = aten::size(%1035) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
                  %1045 : int[] = aten::list(%1044) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
                  %1046 : str = aten::format(%636, %1037, %1045) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
                   = prim::RaiseException(%1046, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
                  -> ()
                block1():
                  -> ()
              %1047 : Tensor = prim::TupleIndex(%hx2.1, %662)
              %mini_batch.7 : int = aten::size(%input0.2, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:679:25
              %1049 : (int, int, int) = prim::TupleConstruct(%659, %mini_batch.7, %639)
              %1050 : int[] = aten::size(%1047) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
              %1051 : int, %1052 : int, %1053 : int = prim::TupleUnpack(%1049)
              %1054 : int[] = prim::ListConstruct(%1051, %1052, %1053)
              %1055 : bool = aten::ne(%1050, %1054) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
               = prim::If(%1055) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
                block0():
                  %1056 : int[] = aten::size(%1047) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
                  %1057 : int[] = aten::list(%1056) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
                  %1058 : str = aten::format(%635, %1049, %1057) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
                   = prim::RaiseException(%1058, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
                  -> ()
                block1():
                  -> ()
              %_flat_weights.2 : Tensor[] = prim::GetAttr[name="_flat_weights"](%rnn.1)
              %training.2 : bool = prim::GetAttr[name="training"](%rnn.1)
              %1061 : Tensor, %1062 : Tensor = prim::TupleUnpack(%hx2.1)
              %1063 : Tensor[] = prim::ListConstruct(%1061, %1062)
              %1064 : Tensor, %1065 : Tensor, %1066 : Tensor = aten::lstm(%input0.2, %1063, %_flat_weights.2, %654, %659, %647, %training.2, %663, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:769:21
              %hidden.2 : (Tensor, Tensor) = prim::TupleConstruct(%1065, %1066)
              %1068 : bool = aten::__not__(%is_batched.2) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:15
              %hidden0.1 : (Tensor, Tensor), %output.1 : Tensor = prim::If(%1068) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:12
                block0():
                  %output0.2 : Tensor = aten::squeeze(%1064, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:782:25
                  %1072 : Tensor = aten::squeeze(%1065, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:26
                  %1073 : Tensor = aten::squeeze(%1066, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:48
                  %hidden1.2 : (Tensor, Tensor) = prim::TupleConstruct(%1072, %1073)
                  -> (%hidden1.2, %output0.2)
                block1():
                  -> (%hidden.2, %1064)
              %1075 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output.1, %hidden0.1)
              %x9.1 : Tensor, %1077 : (Tensor, Tensor) = prim::TupleUnpack(%1075)
              %h2.1 : Tensor, %c2.1 : Tensor = prim::TupleUnpack(%1077)
              -> (%x9.1, %h2.1, %c2.1)
            block1():
              %rnn : __torch__.torch.nn.modules.rnn.___torch_mangle_39.LSTM = prim::GetAttr[name="rnn"](%decoder.2)
              %1081 : int[] = prim::ListConstruct(%657, %659, %662)
              %1082 : Tensor = aten::permute(%x3.1, %1081) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:237:33
              %1083 : int = aten::dim(%1082) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
              %is_batched.1 : bool = aten::eq(%1083, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:731:25
              %1085 : bool = aten::__not__(%is_batched.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:15
              %input0 : Tensor = prim::If(%1085) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:733:12
                block0():
                  %input0.6 : Tensor = aten::unsqueeze(%1082, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:734:24
                  -> (%input0.6)
                block1():
                  -> (%1082)
              %max_batch_size.1 : int = aten::size(%input0, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:735:29
              %1089 : int = prim::dtype(%input0) # :0:0
              %1090 : Device = prim::device(%input0) # :0:0
              %1091 : int[] = prim::ListConstruct(%659, %max_batch_size.1, %639)
              %h_zeros.1 : Tensor = aten::zeros(%1091, %1089, %664, %1090, %664) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:742:22
              %1093 : int = prim::dtype(%input0) # :0:0
              %1094 : Device = prim::device(%input0) # :0:0
              %1095 : int[] = prim::ListConstruct(%659, %max_batch_size.1, %639)
              %c_zeros.1 : Tensor = aten::zeros(%1095, %1093, %664, %1094, %664) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:745:22
              %hx0.1 : (Tensor, Tensor) = prim::TupleConstruct(%h_zeros.1, %c_zeros.1)
              %1098 : int = aten::dim(%input0) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
              %1099 : bool = aten::ne(%1098, %640) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:11
               = prim::If(%1099) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:200:8
                block0():
                  %1100 : int = aten::dim(%input0) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:203:40
                  %1101 : str = aten::format(%637, %640, %1100) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:202:16
                   = prim::RaiseException(%1101, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:201:12
                  -> ()
                block1():
                  -> ()
              %1102 : int = aten::size(%input0, %656) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:30
              %1103 : bool = aten::ne(%639, %1102) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:11
               = prim::If(%1103) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:204:8
                block0():
                  %1104 : int = aten::size(%input0, %656) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:207:37
                  %1105 : str = aten::format(%638, %639, %1104) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:206:16
                   = prim::RaiseException(%1105, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:205:12
                  -> ()
                block1():
                  -> ()
              %1106 : Tensor = prim::TupleIndex(%hx0.1, %657)
              %mini_batch.4 : int = aten::size(%input0, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:213:25
              %1108 : (int, int, int) = prim::TupleConstruct(%659, %mini_batch.4, %639)
              %1109 : int[] = aten::size(%1106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
              %1110 : int, %1111 : int, %1112 : int = prim::TupleUnpack(%1108)
              %1113 : int[] = prim::ListConstruct(%1110, %1111, %1112)
              %1114 : bool = aten::ne(%1109, %1113) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
               = prim::If(%1114) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
                block0():
                  %1115 : int[] = aten::size(%1106) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
                  %1116 : int[] = aten::list(%1115) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
                  %1117 : str = aten::format(%636, %1108, %1116) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
                   = prim::RaiseException(%1117, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
                  -> ()
                block1():
                  -> ()
              %1118 : Tensor = prim::TupleIndex(%hx0.1, %662)
              %mini_batch.1 : int = aten::size(%input0, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:679:25
              %1120 : (int, int, int) = prim::TupleConstruct(%659, %mini_batch.1, %639)
              %1121 : int[] = aten::size(%1118) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
              %1122 : int, %1123 : int, %1124 : int = prim::TupleUnpack(%1120)
              %1125 : int[] = prim::ListConstruct(%1122, %1123, %1124)
              %1126 : bool = aten::ne(%1121, %1125) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:11
               = prim::If(%1126) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:225:8
                block0():
                  %1127 : int[] = aten::size(%1118) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:69
                  %1128 : int[] = aten::list(%1127) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:64
                  %1129 : str = aten::format(%635, %1120, %1128) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:31
                   = prim::RaiseException(%1129, %643) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:226:12
                  -> ()
                block1():
                  -> ()
              %_flat_weights.1 : Tensor[] = prim::GetAttr[name="_flat_weights"](%rnn)
              %training.1 : bool = prim::GetAttr[name="training"](%rnn)
              %1132 : Tensor, %1133 : Tensor = prim::TupleUnpack(%hx0.1)
              %1134 : Tensor[] = prim::ListConstruct(%1132, %1133)
              %1135 : Tensor, %1136 : Tensor, %1137 : Tensor = aten::lstm(%input0, %1134, %_flat_weights.1, %654, %659, %647, %training.1, %663, %654) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:769:21
              %hidden.1 : (Tensor, Tensor) = prim::TupleConstruct(%1136, %1137)
              %1139 : bool = aten::__not__(%is_batched.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:15
              %hidden0 : (Tensor, Tensor), %output : Tensor = prim::If(%1139) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:781:12
                block0():
                  %output0.1 : Tensor = aten::squeeze(%1135, %657) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:782:25
                  %1143 : Tensor = aten::squeeze(%1136, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:26
                  %1144 : Tensor = aten::squeeze(%1137, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py:783:48
                  %hidden1.1 : (Tensor, Tensor) = prim::TupleConstruct(%1143, %1144)
                  -> (%hidden1.1, %output0.1)
                block1():
                  -> (%hidden.1, %1135)
              %1146 : (Tensor, (Tensor, Tensor)) = prim::TupleConstruct(%output, %hidden0)
              %x10.1 : Tensor, %1148 : (Tensor, Tensor) = prim::TupleUnpack(%1146)
              %h3.1 : Tensor, %c3.1 : Tensor = prim::TupleUnpack(%1148)
              -> (%x10.1, %h3.1, %c3.1)
          %1151 : int[] = prim::ListConstruct(%657, %659, %662)
          %x11.1 : Tensor = aten::permute(%x8, %1151) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:239:12
          %decoder.1 : __torch__.torch.nn.modules.container.___torch_mangle_40.Sequential = prim::GetAttr[name="decoder"](%decoder.2)
          %_1 : __torch__.torch.nn.modules.conv.___torch_mangle_41.Conv1d = prim::GetAttr[name="1"](%decoder.1)
          %input0.1 : Tensor = aten::relu(%x11.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1457:17
          %weight.1 : Tensor = prim::GetAttr[name="weight"](%_1)
          %bias.1 : Tensor? = prim::GetAttr[name="bias"](%_1)
          %1158 : int[] = prim::ListConstruct(%662)
          %1159 : int[] = prim::ListConstruct(%657)
          %1160 : int[] = prim::ListConstruct(%662)
          %input1.1 : Tensor = aten::conv1d(%input0.1, %weight.1, %bias.1, %1158, %1159, %1160, %662) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py:303:15
          %x12.1 : Tensor = aten::sigmoid(%input1.1) # /opt/conda/lib/python3.7/site-packages/torch/nn/modules/activation.py:290:15
          %1163 : (Tensor, Tensor, Tensor) = prim::TupleConstruct(%x12.1, %h1, %c1)
          %x4.1 : Tensor, %h0.1 : Tensor, %c0.1 : Tensor = prim::TupleUnpack(%1163)
          %1167 : Tensor = aten::squeeze(%x4.1, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
          %1168 : int[] = prim::ListConstruct(%662)
          %1169 : Tensor = aten::mean(%1167, %1168, %663, %664) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
          %out.1 : Tensor = aten::unsqueeze(%1169, %662) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:302:14
          %1171 : (Tensor, Tensor, Tensor) = prim::TupleConstruct(%out.1, %h0.1, %c0.1)
          %out2.1 : Tensor, %44 : Tensor, %45 : Tensor = prim::TupleUnpack(%1171)
           = prim::SetAttr[name="_h"](%self.1, %44)
           = prim::SetAttr[name="_c"](%self.1, %45)
          -> (%out2.1)
        block1():
           = prim::RaiseException(%4, %3) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:381:12
          -> (%10)
      -> (%out1)
   = prim::SetAttr[name="_last_sr"](%self.1, %sr0.1)
  %_h : Tensor = prim::GetAttr[name="_h"](%self.1)
  %47 : int[] = aten::size(%_h) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:384:32
  %48 : int = aten::__getitem__(%47, %9) # /home/keras/notebook/nvme_raid/adamnsandle/silero-models-research/vad/model/vad_annotator.py:384:32
   = prim::SetAttr[name="_last_batch_size"](%self.1, %48)
  return (%out)

